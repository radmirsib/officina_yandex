{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4097ffc3",
   "metadata": {},
   "source": [
    "## GeoNames\n",
    "\n",
    "\n",
    "## Описание проекта:\n",
    "### Цель исследования:\n",
    "Cопоставление гео-названий с унифицированными именами GeoNames для внутреннего использования Карьерным центром Яндекс Практикума.\n",
    "\n",
    "\n",
    "### Задачи:\n",
    "\n",
    "- Создать решение для подбора наиболее подходящих названий с GeoNames. Например, Ереван -> Yerevan.\n",
    "\n",
    "- На примере РФ и стран наиболее популярных для релокации - Беларусь, Армения, Казахстан, Кыргызстан, Турция, Сербия. Города с населением от 15000 человек (с возможностью масштабирования на сервере заказчика).\n",
    "\n",
    "- Возвращаемые поля geonameid, name, region, country, cosine similarity.\n",
    "\n",
    "- Формат данных на выходе: список словарей, например [{dict_1}, {dict_2}, …. {dict_n}] где словарь - одна запись с указанными полями.\n",
    "\n",
    "\n",
    "### Исходные данные:\n",
    "\n",
    "Используемые таблицы [GeoNames](https://download.geonames.org/export/dump/) и их описание:\n",
    "\n",
    "- `cities15000.txt` - все города с населением > 15 000 или столицы (около 25 000), столбцы см. в таблице `geoname`;\n",
    "\n",
    "- `admin1CodesASCII.txt` - названия на английском языке для административных подразделений. Столбцы: `code, name, name ascii, geonameid`;\n",
    "\n",
    "- `alternateNamesV2.zip` - альтернативные имена с кодами языков и `geonameId`, файл с кодами языков ISO, с новыми столбцами от и до;\n",
    "\n",
    "- `countryInfo.txt` - информация о стране: iso codes, fips codes, languages, capital,...;\n",
    "\n",
    "- `geo_test.csv` - тестовый датасет для проверки нашей модели.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "731908b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install SQLAlchemy\n",
    "#!pip install --pre SQLAlchemy\n",
    "#!pip install psycopg2\n",
    "#!pip install googletrans==3.1.0a0\n",
    "#!pip install sentence-transformers\n",
    "#!pip install fuzzywuzzy\n",
    "#!pip install -r requirements_notebook.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e9d83e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import googletrans\n",
    "import sqlalchemy as sa\n",
    "import psycopg2 as ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68d8a769",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\anaconda3\\lib\\site-packages\\fuzzywuzzy\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, losses, InputExample, util\n",
    "from torch.utils.data import DataLoader\n",
    "from fuzzywuzzy import fuzz, process\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from scipy.spatial import distance\n",
    "from sqlalchemy import create_engine, text\n",
    "from sqlalchemy.engine.url import URL\n",
    "from psycopg2.extensions import ISOLATION_LEVEL_AUTOCOMMIT\n",
    "from googletrans import Translator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589072ee-ae00-42c6-b284-2c6a6f6b5bae",
   "metadata": {},
   "source": [
    "Нам необходимо создать механизм сопоставления произвольных географических названий с унифицированными именами из `GeoNames` для внутреннего использования Карьерным центром Яндекс Практикума. У нас уже есть база данных на сервере, и чтобы обеспечить масштабируемость решения, мы планируем создать собственную базу данных с помощью библиотеки `sqlalchemy`. Эта библиотека позволяет нам описывать структуру баз данных и взаимодействовать с ними на языке Python, без необходимости использования SQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2f11be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATABASE = {\n",
    "    'drivername': 'postgresql',\n",
    "    'username': 'postgres', \n",
    "    'password': '369963', \n",
    "    'host': 'localhost',\n",
    "    'port': 5432,\n",
    "    'database': 'postgres',\n",
    "    'query': {}\n",
    "}  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6838575a",
   "metadata": {},
   "source": [
    "Создаем базу данных PostgreSQL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81d4aa5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выполнение соединения\n",
    "connection = ps.connect(user=\"postgres\", password=\"369963\")\n",
    "connection.set_isolation_level(ISOLATION_LEVEL_AUTOCOMMIT)\n",
    "\n",
    "# Создание курсора\n",
    "cursor = connection.cursor()\n",
    "\n",
    "# Создаем БД\n",
    "#sql_create_database = cursor.execute('create database data_base')\n",
    "\n",
    "# Закрываем соединение\n",
    "cursor.close()\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3389b1",
   "metadata": {},
   "source": [
    "Для реализации объекта движка (Engine) в процессе разработки используется специальная функция create_engine() из библиотеки sqlalchemy. Эта функция предоставляет базовый функционал и позволяет принимать только строку подключения или, как альтернативу, через конструкцию URL(**DATABASE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d9559c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_20264\\3283445818.py:2: SADeprecationWarning: Calling URL() directly is deprecated and will be disabled in a future release.  The public constructor for URL is now the URL.create() method.\n",
      "  engine = create_engine(URL(**DATABASE))\n"
     ]
    }
   ],
   "source": [
    "# engine = create_engine('postgresql://postgres:369963@localhost:5432/postgres')\n",
    "engine = create_engine(URL(**DATABASE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c089853",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engine(postgresql://postgres:***@localhost:5432/postgres)\n"
     ]
    }
   ],
   "source": [
    "engine.connect()\n",
    "print(engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f77069f",
   "metadata": {},
   "source": [
    "Соединение выполнено, начиинаем выгрузку таблиц."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c487eb2",
   "metadata": {},
   "source": [
    "Основными местами релокации специалистов стали соседние страны - Беларусь, Армения, Казахстан, Кыргызстан, Турция, Сербия (эти страны также указаны в ТЗ), соответственно, включаем Россию тоже. Далее будем работать с этими странами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb03ad4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "RELOC = ['RU', 'BY', 'AM', 'KZ', 'KG', 'TR', 'RS']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d5ab85",
   "metadata": {},
   "source": [
    "####  cities15000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03afc8be",
   "metadata": {},
   "source": [
    "Загрузим таблицу, в которой содержатся данные о городах с населением, превышающем 15 тысяч человек, с учетом заданных условий для потенциальной релокации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2ce88b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geonameid</th>\n",
       "      <th>name</th>\n",
       "      <th>name_ascii</th>\n",
       "      <th>alternate_names</th>\n",
       "      <th>country_code</th>\n",
       "      <th>admin1_code</th>\n",
       "      <th>population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20699</th>\n",
       "      <td>546521</td>\n",
       "      <td>Kol’chugino</td>\n",
       "      <td>Kol'chugino</td>\n",
       "      <td>Kellerovo,Kol'chugino,Koltschugino,Koltsjugino...</td>\n",
       "      <td>RU</td>\n",
       "      <td>83</td>\n",
       "      <td>45912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16255</th>\n",
       "      <td>1518518</td>\n",
       "      <td>Talghar</td>\n",
       "      <td>Talghar</td>\n",
       "      <td>Talgar,Talghar,Талгар,Талғар</td>\n",
       "      <td>KZ</td>\n",
       "      <td>01</td>\n",
       "      <td>42194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20625</th>\n",
       "      <td>536164</td>\n",
       "      <td>Tsaritsyno</td>\n",
       "      <td>Tsaritsyno</td>\n",
       "      <td>Caricino,Caricyno,Imeni Chkalova V.P.,Imeni V....</td>\n",
       "      <td>RU</td>\n",
       "      <td>48</td>\n",
       "      <td>123000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16271</th>\n",
       "      <td>1520172</td>\n",
       "      <td>Petropavl</td>\n",
       "      <td>Petropavl</td>\n",
       "      <td>Kizilyar,Kızılyar,PPK,Petropavel,Petropavl,Pet...</td>\n",
       "      <td>KZ</td>\n",
       "      <td>16</td>\n",
       "      <td>200920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20335</th>\n",
       "      <td>490466</td>\n",
       "      <td>Sortavala</td>\n",
       "      <td>Sortavala</td>\n",
       "      <td>Sordavala,Sordovala,Sorravala,Sortaval,Sortava...</td>\n",
       "      <td>RU</td>\n",
       "      <td>28</td>\n",
       "      <td>20760</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       geonameid         name   name_ascii  \\\n",
       "20699     546521  Kol’chugino  Kol'chugino   \n",
       "16255    1518518      Talghar      Talghar   \n",
       "20625     536164   Tsaritsyno   Tsaritsyno   \n",
       "16271    1520172    Petropavl    Petropavl   \n",
       "20335     490466    Sortavala    Sortavala   \n",
       "\n",
       "                                         alternate_names country_code  \\\n",
       "20699  Kellerovo,Kol'chugino,Koltschugino,Koltsjugino...           RU   \n",
       "16255                       Talgar,Talghar,Талгар,Талғар           KZ   \n",
       "20625  Caricino,Caricyno,Imeni Chkalova V.P.,Imeni V....           RU   \n",
       "16271  Kizilyar,Kızılyar,PPK,Petropavel,Petropavl,Pet...           KZ   \n",
       "20335  Sordavala,Sordovala,Sorravala,Sortaval,Sortava...           RU   \n",
       "\n",
       "      admin1_code  population  \n",
       "20699          83       45912  \n",
       "16255          01       42194  \n",
       "20625          48      123000  \n",
       "16271          16      200920  \n",
       "20335          28       20760  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities_15000 = pd.read_table('D:/DS/M2_Geonames/info/data/cities15000.txt',\n",
    "                     sep='\\t', \n",
    "                     header=None,\n",
    "                     names=[\n",
    "                         'geonameid', \n",
    "                         'name', \n",
    "                         'name_ascii',\n",
    "                         'alternate_names',\n",
    "                         'latitude',\n",
    "                         'longitude',\n",
    "                         'feature_class',\n",
    "                         'feature_code',\n",
    "                         'country_code',\n",
    "                         'cc2','admin1_code',\n",
    "                         'admin2_code',\n",
    "                         'admin3_code',\n",
    "                         'admin4_code',\n",
    "                         'population',\n",
    "                         'elevation',\n",
    "                         'dem',\n",
    "                         'timezone',\n",
    "                         'modification_date'],\n",
    "                    usecols=[\n",
    "                        'geonameid',\n",
    "                        'name',\n",
    "                        'name_ascii',\n",
    "                        'alternate_names',\n",
    "                        'country_code',\n",
    "                        'admin1_code',\n",
    "                        'population'\n",
    "                    ]).dropna()\n",
    "\n",
    "cities_reloc = cities_15000.query('country_code in @RELOC')\n",
    "cities_reloc.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6683b5af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество городов после фильтрации:  1692\n",
      "Количество городов (уникальные):  1667\n"
     ]
    }
   ],
   "source": [
    "print('Количество городов после фильтрации: ', cities_reloc.shape[0])\n",
    "print('Количество городов (уникальные): ', cities_reloc.name.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8bc993",
   "metadata": {},
   "source": [
    "В целях обеспечения более эффективной обработки данных, произведем объединение списков с альтернативными названиями в одну колонку и проведем очистку данных от дубликатов. Кроме того, мы также удалим явные дублирующиеся строки для повышения качества и точности данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02b6d3e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_20264\\2415893823.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cities_reloc['alternate_names'] = cities_reloc['alternate_names'].str.split(',')\n"
     ]
    }
   ],
   "source": [
    "cities_reloc['alternate_names'] = cities_reloc['alternate_names'].str.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8205bd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_reloc = cities_reloc.explode('alternate_names').drop_duplicates(subset=['name', 'alternate_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "393ce3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_reloc = cities_reloc.query('name != alternate_names')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3007d81e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of        geonameid             name         name_ascii alternate_names  \\\n",
       "94        174875            Kapan              Kapan         Ghap'an   \n",
       "94        174875            Kapan              Kapan          Ghapan   \n",
       "94        174875            Kapan              Kapan         Ghap’an   \n",
       "94        174875            Kapan              Kapan           Kafan   \n",
       "94        174875            Kapan              Kapan           Kafin   \n",
       "...          ...              ...                ...             ...   \n",
       "22600    6354985  güngören merter  guengoeren merter          Merter   \n",
       "22602    6692524        Sarigerme          Sarigerme       Саригерме   \n",
       "22605    6947640       Beylikdüzü       Beylikduezue      Beylikduzu   \n",
       "22607    6955677          Çankaya            Cankaya         Cankaya   \n",
       "22613    8074174        Muratpaşa          Muratpasa       Muratpasa   \n",
       "\n",
       "      country_code admin1_code  population  \n",
       "94              AM          08       33160  \n",
       "94              AM          08       33160  \n",
       "94              AM          08       33160  \n",
       "94              AM          08       33160  \n",
       "94              AM          08       33160  \n",
       "...            ...         ...         ...  \n",
       "22600           TR          34       50000  \n",
       "22602           TR          48       16000  \n",
       "22605           TR          34      122452  \n",
       "22607           TR          68      792189  \n",
       "22613           TR          07      450000  \n",
       "\n",
       "[22722 rows x 7 columns]>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities_reloc.head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4701d8",
   "metadata": {},
   "source": [
    "Выполним подсчёт вспомогательного столбца для связи с таблицей `admin1CodesASCII` по двум уже имеющимся"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7fd8d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_reloc['code'] = cities_reloc.country_code + '.' + cities_reloc.admin1_code\n",
    "cities_reloc = cities_reloc.drop('admin1_code', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "64d0ed46-681f-40bf-96b2-f076b0f901b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22722, 7)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities_reloc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b369f782",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geonameid</th>\n",
       "      <th>name</th>\n",
       "      <th>name_ascii</th>\n",
       "      <th>alternate_names</th>\n",
       "      <th>country_code</th>\n",
       "      <th>population</th>\n",
       "      <th>code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20280</th>\n",
       "      <td>480562</td>\n",
       "      <td>Tula</td>\n",
       "      <td>Tula</td>\n",
       "      <td>Tul</td>\n",
       "      <td>RU</td>\n",
       "      <td>482873</td>\n",
       "      <td>RU.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22364</th>\n",
       "      <td>315368</td>\n",
       "      <td>Erzurum</td>\n",
       "      <td>Erzurum</td>\n",
       "      <td>ارض روم</td>\n",
       "      <td>TR</td>\n",
       "      <td>767848</td>\n",
       "      <td>TR.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20721</th>\n",
       "      <td>548652</td>\n",
       "      <td>Kimry</td>\n",
       "      <td>Kimry</td>\n",
       "      <td>kymry</td>\n",
       "      <td>RU</td>\n",
       "      <td>52070</td>\n",
       "      <td>RU.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22256</th>\n",
       "      <td>300619</td>\n",
       "      <td>Sivas</td>\n",
       "      <td>Sivas</td>\n",
       "      <td>sywas</td>\n",
       "      <td>TR</td>\n",
       "      <td>264022</td>\n",
       "      <td>TR.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21050</th>\n",
       "      <td>1498894</td>\n",
       "      <td>Miass</td>\n",
       "      <td>Miass</td>\n",
       "      <td>Miasas</td>\n",
       "      <td>RU</td>\n",
       "      <td>167500</td>\n",
       "      <td>RU.13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       geonameid     name name_ascii alternate_names country_code  population  \\\n",
       "20280     480562     Tula       Tula             Tul           RU      482873   \n",
       "22364     315368  Erzurum    Erzurum         ارض روم           TR      767848   \n",
       "20721     548652    Kimry      Kimry           kymry           RU       52070   \n",
       "22256     300619    Sivas      Sivas           sywas           TR      264022   \n",
       "21050    1498894    Miass      Miass          Miasas           RU      167500   \n",
       "\n",
       "        code  \n",
       "20280  RU.76  \n",
       "22364  TR.25  \n",
       "20721  RU.77  \n",
       "22256  TR.58  \n",
       "21050  RU.13  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities_reloc.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4551925",
   "metadata": {},
   "source": [
    "Была выполнена загрузка файла данных в датафрейм, после чего произведено фильтрование данных для выбранных стран. Далее был расширен столбец с альтернативными названиями, чтобы каждое название занимало отдельную строку в столбце. Затем произведена очистка датафрейма от дубликатов и совпадающих значений в столбцах с названиями и альтернативными названиями. В завершение операции, полученный результат будет выгружен в созданную базу данных."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c72b56c",
   "metadata": {},
   "source": [
    "#### admin1CodesASCII"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "441b057f",
   "metadata": {},
   "outputs": [],
   "source": [
    "admin_codes = pd.read_table('D:/DS/M2_Geonames/info/data/admin1CodesASCII.txt',\n",
    "                     sep='\\t',\n",
    "                     header=None,\n",
    "                     names=[\n",
    "                         'code', \n",
    "                         'region', \n",
    "                         'name_ascii', \n",
    "                         'geonameid'\n",
    "                     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "81d723a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>region</th>\n",
       "      <th>name_ascii</th>\n",
       "      <th>geonameid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2765</th>\n",
       "      <td>RU.73</td>\n",
       "      <td>Tatarstan Republic</td>\n",
       "      <td>Tatarstan Republic</td>\n",
       "      <td>484048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>DE.16</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>2950157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AD.03</td>\n",
       "      <td>Encamp</td>\n",
       "      <td>Encamp</td>\n",
       "      <td>3040684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2035</th>\n",
       "      <td>MK.46</td>\n",
       "      <td>Kochani</td>\n",
       "      <td>Kochani</td>\n",
       "      <td>863865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3017</th>\n",
       "      <td>SI.53</td>\n",
       "      <td>Kranjska Gora</td>\n",
       "      <td>Kranjska Gora</td>\n",
       "      <td>3239105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       code              region          name_ascii  geonameid\n",
       "2765  RU.73  Tatarstan Republic  Tatarstan Republic     484048\n",
       "753   DE.16              Berlin              Berlin    2950157\n",
       "3     AD.03              Encamp              Encamp    3040684\n",
       "2035  MK.46             Kochani             Kochani     863865\n",
       "3017  SI.53       Kranjska Gora       Kranjska Gora    3239105"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "admin_codes.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d68e1804-e1aa-4756-a2f9-67459d174037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3881, 4)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "admin_codes.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddc0388",
   "metadata": {},
   "source": [
    "Для анализа совпадений кодов стран в таблице городов мы установим условие, используя пять случайно выбранных строк из предыдущих данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b732d41a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>region</th>\n",
       "      <th>name_ascii</th>\n",
       "      <th>geonameid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2228</th>\n",
       "      <td>MV.46</td>\n",
       "      <td>Thaa Atholhu</td>\n",
       "      <td>Thaa Atholhu</td>\n",
       "      <td>1281881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2391</th>\n",
       "      <td>NL.09</td>\n",
       "      <td>Utrecht</td>\n",
       "      <td>Utrecht</td>\n",
       "      <td>2745909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>PR.083</td>\n",
       "      <td>Las Marías</td>\n",
       "      <td>Las Marias</td>\n",
       "      <td>4565961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3096</th>\n",
       "      <td>SI.N8</td>\n",
       "      <td>Žužemberk</td>\n",
       "      <td>Zuzemberk</td>\n",
       "      <td>3344909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3844</th>\n",
       "      <td>YT.97610</td>\n",
       "      <td>Koungou</td>\n",
       "      <td>Koungou</td>\n",
       "      <td>7521430</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          code        region    name_ascii  geonameid\n",
       "2228     MV.46  Thaa Atholhu  Thaa Atholhu    1281881\n",
       "2391     NL.09       Utrecht       Utrecht    2745909\n",
       "2612    PR.083    Las Marías    Las Marias    4565961\n",
       "3096     SI.N8     Žužemberk     Zuzemberk    3344909\n",
       "3844  YT.97610       Koungou       Koungou    7521430"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "admin_codes.query('code in (\"PR.083\", \"NL.09\", \"SI.N8\", \"YT.97610\", \"MV.46\")')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ea8b7a",
   "metadata": {},
   "source": [
    "Значения случайно выбранных кодов совпало в двух анализируемых таблицах. В дальнейшей работе из этих данных будем использовать регионы."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5660d343",
   "metadata": {},
   "source": [
    "#### alternateNamesV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ba916963",
   "metadata": {},
   "outputs": [],
   "source": [
    "alter_names = pd.read_table('D:/DS/M2_Geonames/info/data/alternateNamesV2.txt', \n",
    "                     low_memory=False,\n",
    "                     header=None,\n",
    "                     names=[\n",
    "                         'alternate_name_id',\n",
    "                         'geonameid',\n",
    "                         'alternate_lang',\n",
    "                         'alternate_names',\n",
    "                         'is_preferred_name',\n",
    "                         'is_short_name',\n",
    "                         'is_colloquial',\n",
    "                         'is_historic',\n",
    "                         'use_from',\n",
    "                         'use_to'\n",
    "                     ],\n",
    "                    usecols=[\n",
    "                        'alternate_name_id',\n",
    "                        'geonameid',\n",
    "                        'alternate_lang',\n",
    "                        'alternate_names',\n",
    "                        'alternate_names']\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5a4f3e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16051360, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alternate_name_id</th>\n",
       "      <th>geonameid</th>\n",
       "      <th>alternate_lang</th>\n",
       "      <th>alternate_names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7097177</th>\n",
       "      <td>1920407</td>\n",
       "      <td>2522857</td>\n",
       "      <td>nl</td>\n",
       "      <td>Tricase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9237306</th>\n",
       "      <td>8948784</td>\n",
       "      <td>8873402</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tziltzapollo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10306652</th>\n",
       "      <td>9792841</td>\n",
       "      <td>9476442</td>\n",
       "      <td>no</td>\n",
       "      <td>Søre Borgen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          alternate_name_id  geonameid alternate_lang alternate_names\n",
       "7097177             1920407    2522857             nl         Tricase\n",
       "9237306             8948784    8873402            NaN    Tziltzapollo\n",
       "10306652            9792841    9476442             no     Søre Borgen"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(alter_names.shape)\n",
    "alter_names.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb18627f",
   "metadata": {},
   "source": [
    "#### countryInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bc13ef1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_info = pd.read_table('D:/DS/M2_Geonames/info/data/countryInfo.txt', \n",
    "                     header=None, \n",
    "                     names=[\n",
    "                         'country_code', \n",
    "                         'iso_3', \n",
    "                         'iso_numeric',\n",
    "                         'fips',\n",
    "                         'country',\n",
    "                         'capital',\n",
    "                         'area',\n",
    "                         'population',\n",
    "                         'continent',\n",
    "                         'tld',\n",
    "                         'currency_code',\n",
    "                         'currency_name',\n",
    "                         'phone',\n",
    "                         'postal_code_format',\n",
    "                         'postal_code_regex',\n",
    "                         'languages',\n",
    "                         'geonameid',\n",
    "                         'neighbours',\n",
    "                         'equivalent_fips_code'],\n",
    "                    usecols=[\n",
    "                        'geonameid',\n",
    "                        'country_code',\n",
    "                        'country',\n",
    "                        'area',\n",
    "                        'languages',\n",
    "                        'population'\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3b3305e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(302, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country_code</th>\n",
       "      <th>country</th>\n",
       "      <th>area</th>\n",
       "      <th>population</th>\n",
       "      <th>languages</th>\n",
       "      <th>geonameid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>EH</td>\n",
       "      <td>Western Sahara</td>\n",
       "      <td>266000</td>\n",
       "      <td>273008</td>\n",
       "      <td>ar,mey</td>\n",
       "      <td>2461445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>SE</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>449964</td>\n",
       "      <td>10183175</td>\n",
       "      <td>sv-SE,se,sma,fi-SE</td>\n",
       "      <td>2661886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>FJ</td>\n",
       "      <td>Fiji</td>\n",
       "      <td>18270</td>\n",
       "      <td>883483</td>\n",
       "      <td>en-FJ,fj</td>\n",
       "      <td>2205218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>JP</td>\n",
       "      <td>Japan</td>\n",
       "      <td>377835</td>\n",
       "      <td>126529100</td>\n",
       "      <td>ja</td>\n",
       "      <td>1861060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>HK</td>\n",
       "      <td>Hong Kong</td>\n",
       "      <td>1092</td>\n",
       "      <td>7451000</td>\n",
       "      <td>zh-HK,yue,zh,en</td>\n",
       "      <td>1819730</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    country_code         country    area population           languages  \\\n",
       "115           EH  Western Sahara  266000     273008              ar,mey   \n",
       "248           SE          Sweden  449964   10183175  sv-SE,se,sma,fi-SE   \n",
       "120           FJ            Fiji   18270     883483            en-FJ,fj   \n",
       "163           JP           Japan  377835  126529100                  ja   \n",
       "144           HK       Hong Kong    1092    7451000     zh-HK,yue,zh,en   \n",
       "\n",
       "    geonameid  \n",
       "115   2461445  \n",
       "248   2661886  \n",
       "120   2205218  \n",
       "163   1861060  \n",
       "144   1819730  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(country_info.shape)\n",
    "country_info.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ceadc4",
   "metadata": {},
   "source": [
    "#### iso-languagecodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b22a53b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "language_codes = pd.read_table('D:/DS/M2_Geonames/info/data/iso-languagecodes.txt',\n",
    "                     header=None, \n",
    "                     names=[\n",
    "                         'iso_639_3', \n",
    "                         'iso_639_2', \n",
    "                         'iso_639_1',\n",
    "                         'language_name'\n",
    "                     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eb38e1e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iso_639_3</th>\n",
       "      <th>iso_639_2</th>\n",
       "      <th>iso_639_1</th>\n",
       "      <th>language_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6282</th>\n",
       "      <td>tbn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Barro Negro Tunebo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5852</th>\n",
       "      <td>sgj</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Surgujia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4053</th>\n",
       "      <td>mhg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Margu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     iso_639_3 iso_639_2 iso_639_1       language_name\n",
       "6282       tbn       NaN       NaN  Barro Negro Tunebo\n",
       "5852       sgj       NaN       NaN            Surgujia\n",
       "4053       mhg       NaN       NaN               Margu"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "language_codes.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4695b0",
   "metadata": {},
   "source": [
    "#### geo_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "afc8b4e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>name</th>\n",
       "      <th>region</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>Воскресенск</td>\n",
       "      <td>Voskresensk</td>\n",
       "      <td>Moscow Oblast</td>\n",
       "      <td>Russia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Белгород</td>\n",
       "      <td>Belgorod</td>\n",
       "      <td>Belgorod Oblast</td>\n",
       "      <td>Russia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>Братск</td>\n",
       "      <td>Bratsk</td>\n",
       "      <td>Irkutsk Oblast</td>\n",
       "      <td>Russia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>Каракол</td>\n",
       "      <td>Karakol</td>\n",
       "      <td>Issyk-Kul</td>\n",
       "      <td>Kyrgyzstan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Уфа</td>\n",
       "      <td>Ufa</td>\n",
       "      <td>Bashkortostan Republic</td>\n",
       "      <td>Russia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           query         name                  region     country\n",
       "307  Воскресенск  Voskresensk           Moscow Oblast      Russia\n",
       "51      Белгород     Belgorod         Belgorod Oblast      Russia\n",
       "191       Братск       Bratsk          Irkutsk Oblast      Russia\n",
       "218      Каракол      Karakol               Issyk-Kul  Kyrgyzstan\n",
       "23           Уфа          Ufa  Bashkortostan Republic      Russia"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geo_test = pd.read_csv('D:/DS/M2_Geonames/info/data/geo_test.csv', sep=';')\n",
    "geo_test.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c137b57f",
   "metadata": {},
   "source": [
    "**Загрузка таблиц в БД PostgreSQL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2a3634e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#cities_reloc.to_sql('cities_reloc', con=engine)\n",
    "#admin_codes.to_sql('admin_codes_ascii', con=engine)\n",
    "#alter_names.to_sql('alternate_names', con=engine)\n",
    "#country_info.to_sql('country_info', con=engine)\n",
    "#language_codes.to_sql('iso_language_codes', con=engine)\n",
    "#geo_test.to_sql('geo_test', con=engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe777d1",
   "metadata": {},
   "source": [
    "Убедимся в правильности работы соединения с БД"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4e8b2aca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>geonameid</th>\n",
       "      <th>name</th>\n",
       "      <th>name_ascii</th>\n",
       "      <th>alternate_names</th>\n",
       "      <th>country_code</th>\n",
       "      <th>population</th>\n",
       "      <th>code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20731</td>\n",
       "      <td>551487</td>\n",
       "      <td>Kazan</td>\n",
       "      <td>Kazan</td>\n",
       "      <td>Casanum</td>\n",
       "      <td>RU</td>\n",
       "      <td>1243500</td>\n",
       "      <td>RU.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20731</td>\n",
       "      <td>551487</td>\n",
       "      <td>Kazan</td>\n",
       "      <td>Kazan</td>\n",
       "      <td>Caza</td>\n",
       "      <td>RU</td>\n",
       "      <td>1243500</td>\n",
       "      <td>RU.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20731</td>\n",
       "      <td>551487</td>\n",
       "      <td>Kazan</td>\n",
       "      <td>Kazan</td>\n",
       "      <td>Cazã</td>\n",
       "      <td>RU</td>\n",
       "      <td>1243500</td>\n",
       "      <td>RU.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20731</td>\n",
       "      <td>551487</td>\n",
       "      <td>Kazan</td>\n",
       "      <td>Kazan</td>\n",
       "      <td>KZN</td>\n",
       "      <td>RU</td>\n",
       "      <td>1243500</td>\n",
       "      <td>RU.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20731</td>\n",
       "      <td>551487</td>\n",
       "      <td>Kazan</td>\n",
       "      <td>Kazan</td>\n",
       "      <td>Kaasan</td>\n",
       "      <td>RU</td>\n",
       "      <td>1243500</td>\n",
       "      <td>RU.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20731</td>\n",
       "      <td>551487</td>\n",
       "      <td>Kazan</td>\n",
       "      <td>Kazan</td>\n",
       "      <td>Kasa</td>\n",
       "      <td>RU</td>\n",
       "      <td>1243500</td>\n",
       "      <td>RU.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20731</td>\n",
       "      <td>551487</td>\n",
       "      <td>Kazan</td>\n",
       "      <td>Kazan</td>\n",
       "      <td>Kasan</td>\n",
       "      <td>RU</td>\n",
       "      <td>1243500</td>\n",
       "      <td>RU.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20731</td>\n",
       "      <td>551487</td>\n",
       "      <td>Kazan</td>\n",
       "      <td>Kazan</td>\n",
       "      <td>Kasã</td>\n",
       "      <td>RU</td>\n",
       "      <td>1243500</td>\n",
       "      <td>RU.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20731</td>\n",
       "      <td>551487</td>\n",
       "      <td>Kazan</td>\n",
       "      <td>Kazan</td>\n",
       "      <td>Kazan'</td>\n",
       "      <td>RU</td>\n",
       "      <td>1243500</td>\n",
       "      <td>RU.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20731</td>\n",
       "      <td>551487</td>\n",
       "      <td>Kazan</td>\n",
       "      <td>Kazan</td>\n",
       "      <td>Kazan' osh</td>\n",
       "      <td>RU</td>\n",
       "      <td>1243500</td>\n",
       "      <td>RU.73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  geonameid   name name_ascii alternate_names country_code  \\\n",
       "0  20731     551487  Kazan      Kazan         Casanum           RU   \n",
       "1  20731     551487  Kazan      Kazan            Caza           RU   \n",
       "2  20731     551487  Kazan      Kazan            Cazã           RU   \n",
       "3  20731     551487  Kazan      Kazan             KZN           RU   \n",
       "4  20731     551487  Kazan      Kazan          Kaasan           RU   \n",
       "5  20731     551487  Kazan      Kazan            Kasa           RU   \n",
       "6  20731     551487  Kazan      Kazan           Kasan           RU   \n",
       "7  20731     551487  Kazan      Kazan            Kasã           RU   \n",
       "8  20731     551487  Kazan      Kazan          Kazan'           RU   \n",
       "9  20731     551487  Kazan      Kazan      Kazan' osh           RU   \n",
       "\n",
       "   population   code  \n",
       "0     1243500  RU.73  \n",
       "1     1243500  RU.73  \n",
       "2     1243500  RU.73  \n",
       "3     1243500  RU.73  \n",
       "4     1243500  RU.73  \n",
       "5     1243500  RU.73  \n",
       "6     1243500  RU.73  \n",
       "7     1243500  RU.73  \n",
       "8     1243500  RU.73  \n",
       "9     1243500  RU.73  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_sql(sql=text(\"SELECT * FROM cities_reloc WHERE name = 'Kazan' LIMIT 10\"), con=engine.connect())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ba72e6",
   "metadata": {},
   "source": [
    "Приступим к дальнейшей работе"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bee8c0e",
   "metadata": {},
   "source": [
    "## CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73d7424",
   "metadata": {},
   "source": [
    "Решение вопросов в задачах подобного типа начинают с основных терминов, таких как `Сходство Жаккара (Jaccard similarity)`, `Алгоритм шинглов (Shingling algorithm)` и `Растояние Левенштейна (Levenshtein Distance)`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7909c55",
   "metadata": {},
   "source": [
    "`CountVectorizer` - это модуль в библиотеке `scikit-learn` для извлечения признаков из текста. Он преобразует текстовые документы в матрицу, где каждый столбец представляет отдельное слово, а каждая строка представляет документ. Значение ячейки в матрице указывает, сколько раз данное слово встретилось в данном документе. `CountVectorizer` позволяет представить текст в виде численных данных, которые можно использовать для обучения моделей машинного обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d1618c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "corp = pd.read_sql(sql=text(\"SELECT alternate_names FROM cities_reloc WHERE name = 'Kaliningrad'\"), con=engine.connect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "86bc0777",
   "metadata": {},
   "outputs": [],
   "source": [
    "corp_all = pd.read_sql(sql=text(\"SELECT alternate_names FROM cities_reloc\"), con=engine.connect())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0641b7d9",
   "metadata": {},
   "source": [
    "Сформируем корпуса слов, первый в рамках однго города и второй состоящий из всех альтернативных названий всех городов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7a1d7028",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = corp.alternate_names.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9622ae4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "corp_all = corp_all.alternate_names.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "66510d33",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56, 22722)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus), len(corp_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6f5eb938-dcba-4f51-a5c3-e01ce060f9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = cities_reloc.name.drop_duplicates().values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3945e88a",
   "metadata": {},
   "source": [
    "Создадим запрос"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8662c207",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'Калининград'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ed9f7ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(analyzer='char',  strip_accents='unicode', ngram_range=(1, 3),\n",
    "                             lowercase=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5440df30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_count_vectorizer(city, alternatives, n=5):\n",
    "    vectorizer.fit(alternatives)\n",
    "    query_vector = vectorizer.transform([city]).toarray()[0]\n",
    "    word_count_vec = {}\n",
    "    for word in alternatives:\n",
    "        word_vector = vectorizer.transform([word]).toarray()[0]\n",
    "        cosine_similarity = 1 - distance.cosine(word_vector, query_vector)\n",
    "        if cosine_similarity > 0.60:\n",
    "            word_count_vec[word] = word, round(cosine_similarity, 3)\n",
    "    result = []\n",
    "    for word in word_count_vec.values():  \n",
    "        result.append(word)\n",
    "    \n",
    "    result.sort(key=lambda x: x[1], reverse=True)\n",
    "    if n < len(word_count_vec):\n",
    "        return [result[word] for word in range(1, n+1)]\n",
    "    else:\n",
    "        n = len(word_count_vec)\n",
    "        return [result[word] for word in range(n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9bdb6ed8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Калињинград', 0.835),\n",
       " ('Калинин', 0.828),\n",
       " ('Сталинград', 0.783),\n",
       " ('Ленинград', 0.764),\n",
       " ('Калининск', 0.746)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count_vectorizer(query, corp_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b646959",
   "metadata": {},
   "source": [
    "После проведения токенизации текстовых названий и подсчета частоты встречаемости каждого токена, мы произвели преобразование альтернативных названий. Затем мы рассчитали косинусное сходство между каждым названием и используя это расстояние, определили наиболее подходящие названия в порядке убывания. Описанный алгоритм показал хорошие результаты, для правильно написанного города \"Ростов-на-Дону\" было найдено 5 объекта. Далее мы проверили работу алгоритма с ошибками в запросах. Создадим тестовый набор с ошибками в наименовании городов на русском языке:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4fb7f083",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list = ['Ростов в Доне', 'Казаань', 'Колинингрод', 'Масква', 'Сант Питерсбург']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "31a8b9c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ростов в Доне [('Ростов на Дону', 0.809), ('Ростов', 0.723), ('Донын Ростов', 0.722), ('Дондохи Ростов', 0.704), ('Дондағы Ростов', 0.674)]\n",
      "****************************************************************************************************\n",
      "Казаань [('Казан', 0.836), ('Казань ош', 0.736), ('Казањ', 0.724), ('Азак', 0.692), ('Қазан', 0.669)]\n",
      "****************************************************************************************************\n",
      "Колинингрод [('Калининград', 0.684), ('Калинин', 0.629)]\n",
      "****************************************************************************************************\n",
      "Масква [('Маскав', 0.765), ('Москва', 0.689), ('Маскасола', 0.666), ('Новамаскоўск', 0.629), ('Расказава', 0.606)]\n",
      "****************************************************************************************************\n",
      "Сант Питерсбург [('Санкт Петербург', 0.695), ('Санкт Петерзбург', 0.674), ('Санкт-Петербург', 0.611)]\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "for item in test_list:\n",
    "    print(item, word_count_vectorizer(item, corp_all))\n",
    "    print(100*'*')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8bb074",
   "metadata": {},
   "source": [
    "Создадим тестовый набор с ошибочными названиями городов на английскм языке:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f879661a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list_en = ['Sant Piterburg', 'Mognitogarsk',  'Krosnadar',  'Khobarovsk',  'Odintsogo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "43df37e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sant Piterburg [('Saint Petersburg', 0.729)]\n",
      "****************************************************************************************************\n",
      "Mognitogarsk [('Magnitogorsk', 0.763)]\n",
      "****************************************************************************************************\n",
      "Krosnadar [('Krasnodar', 0.643)]\n",
      "****************************************************************************************************\n",
      "Khobarovsk [('Khabarovsk', 0.806), ('Khabarovsk Vtoroy', 0.718), ('Kirovsk', 0.643)]\n",
      "****************************************************************************************************\n",
      "Odintsogo [('Odintsovo', 0.833), ('Bogoroditsk', 0.639)]\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "for item in test_list_en:\n",
    "    print(item, word_count_vectorizer(item, names))\n",
    "    print(100*'*')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbaaa7ad",
   "metadata": {},
   "source": [
    "`CountVectorizer` имеет некоторые ограничения, связанные с его пониманием семантики. Он обрабатывает каждый токен отдельно, без учета семантических связей. Попробуем провести анализ с использованием `TfidfVectorizer`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b85684",
   "metadata": {},
   "source": [
    "## TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af46b566",
   "metadata": {},
   "source": [
    "`TfidfVectorizer (Tf-idf Vectorizer)` - это модуль в библиотеке `scikit-learn` для извлечения информационного отношения между словами в текстовом корпусе. Он представляет текстовые данные в виде матрицы, используя векторное представление на основе `TF-IDF (Term Frequency-Inverse Document Frequency)`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5e8919",
   "metadata": {},
   "source": [
    "`TF-IDF` - это статистическая мера, используемая для оценки важности слов в документе внутри коллекции документов. Она учитывает как частоту слова в документе (`TF - Term Frequency`), так и обратную частоту слова во всей коллекции документов (`IDF - Inverse Document Frequency`). Это позволяет выделить наиболее информативные слова, которые характерны для конкретного документа и имеют низкую частоту в других документах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7cdb5005",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_tfidf = TfidfVectorizer(analyzer='char',ngram_range=(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e13b2023",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_tfidf_vectorizer(city, alternatives, n=5):\n",
    "    # Преобразование корпуса\n",
    "    vectorizer_tfidf.fit(alternatives)\n",
    "    query_vector_tfidf = vectorizer_tfidf.transform([city]).toarray()[0]\n",
    "    word_count_vec_tfidf = {}\n",
    "    for word in alternatives:\n",
    "        word_vector_tfidf = vectorizer_tfidf.transform([word]).toarray()[0]\n",
    "        cosine_similarity_tfidf = 1 - distance.cosine(word_vector_tfidf, query_vector_tfidf)\n",
    "    \n",
    "        if cosine_similarity_tfidf > 0.60:\n",
    "            word_count_vec_tfidf[word] = round(cosine_similarity_tfidf, 3)\n",
    "\n",
    "    result_tfidf = sorted(word_count_vec_tfidf.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    if n < len(word_count_vec_tfidf):\n",
    "        return [result_tfidf[i] for i in range(n)]\n",
    "    else:\n",
    "        return [result_tfidf[i] for i in range(len(word_count_vec_tfidf))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b44bcbd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Калининград', 1),\n",
       " ('Сталинград', 0.806),\n",
       " ('Ленинград', 0.8),\n",
       " ('Калинин', 0.798),\n",
       " ('Калињинград', 0.77)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tfidf_vectorizer(query, corp_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f21ddac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ростов в Доне [('Ростов на Дон', 0.795), ('Ростов на Дону', 0.758), ('Ростов', 0.606)]\n",
      "****************************************************************************************************\n",
      "Казаань [('Казань', 0.912), ('Казан', 0.81), ('Казань ош', 0.685), ('Азак', 0.642), ('Козань', 0.637)]\n",
      "****************************************************************************************************\n",
      "Колинингрод [('Калининград', 0.739), ('Калинин', 0.642), ('Ленинград', 0.628)]\n",
      "****************************************************************************************************\n",
      "Масква [('Масква', 1), ('Москва', 0.712), ('Маскав', 0.69), ('Уква', 0.619), ('Маскасола', 0.608)]\n",
      "****************************************************************************************************\n",
      "Сант Питерсбург [('Санкт Петербург', 0.706), ('Санкт Петерзбург', 0.664)]\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "for item in test_list:\n",
    "    print(item, word_tfidf_vectorizer(item, corp_all))\n",
    "    print(100*'*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "91577e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sant Piterburg [('Saint Petersburg', 0.713)]\n",
      "****************************************************************************************************\n",
      "Mognitogarsk [('Magnitogorsk', 0.782)]\n",
      "****************************************************************************************************\n",
      "Krosnadar [('Krasnodar', 0.657), ('Adana', 0.603)]\n",
      "****************************************************************************************************\n",
      "Khobarovsk [('Khabarovsk', 0.742), ('Obukhovo', 0.614)]\n",
      "****************************************************************************************************\n",
      "Odintsogo [('Odintsovo', 0.836), ('Bogoroditsk', 0.679)]\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "for item in test_list_en:\n",
    "    print(item, word_tfidf_vectorizer(item, names))\n",
    "    print(100*'*')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a584e29c",
   "metadata": {},
   "source": [
    "## Levenshtein Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5596420a",
   "metadata": {},
   "source": [
    "`Растояние Левенштейна (редакционное расстояние)` представляет собой метрику для измерения разницы между двумя строками в терминах операций вставки, удаления и замены символов. Оно измеряет минимальное количество таких операций, необходимых для превращения одной строки в другую.\n",
    "\n",
    "Основные операции редакционного расстояния включают вставку (добавление символа в одну из строк), удаление (удаление символа из одной из строк) и замену (замена одного символа на другой). Дополнительно может быть учтена операция транспозиции (перестановка двух соседних символов).\n",
    "\n",
    "Используем библиотеку `FuzzyWuzzy` для нечёткого сравнения строк."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773a9f06",
   "metadata": {},
   "source": [
    "Для сравнения строки со строками из списка используем модуль process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f7434d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Калининград', 100)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Калининград', 100)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(process.extractOne(query, corpus))\n",
    "process.extractOne(query, corp_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "467a15b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Калининград', 100), ('Калињинград', 91), ('Калінінград', 82), ('Caliningrado', 0), ('Calininopolis', 0), ('KGD', 0), (\"Kalinin'nkrant\", 0), ('Kaliningrada', 0), ('Kaliningradas', 0), ('Kaliningrado', 0)]\n"
     ]
    }
   ],
   "source": [
    "result_fuzzy = process.extract(query, corpus, limit=None)\n",
    "print(result_fuzzy[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9c794978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Калининград', 100), ('Калининград', 100), ('Калињинград', 91), ('Калинин', 90), ('Калінінград', 82), ('Ленинград', 80), ('Сталинград', 76), ('Клинци', 75), ('Ливни', 72), ('Кашин', 72)]\n"
     ]
    }
   ],
   "source": [
    "result_fuzzy_all = process.extract(query, corp_all, limit=None)\n",
    "print(result_fuzzy_all[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "64b9da4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(result):\n",
    "    count = 0\n",
    "    for i in range(len(result_fuzzy)):\n",
    "        count+=result[i][1]\n",
    "    return print('Levenshtein Distance = ', round(count/len(result), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ff49bfcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Levenshtein Distance =  4.88\n"
     ]
    }
   ],
   "source": [
    "accuracy(result_fuzzy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08027f7f",
   "metadata": {},
   "source": [
    "Анализ результатов показал, что алгоритм достаточно успешно справляется с запросами на одном языке, даже в случае использования русского языка, где он пытается находить соответствия. В целом, результаты поиска во всем корпусе хорошие. Но для более детального изучения мы хотим создать алгоритм, который будет работать с запросами на любых языках и учитывать различные варианты написания.\n",
    "\n",
    "Для улучшения этого метода мы попробуем использовать библиотеку `Googletrans`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "119d45f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def translator(corpus_word):\n",
    "    translator= Translator(service_urls=['translate.googleapis.com'])\n",
    "    translations = translator.translate(corpus_word, dest='ru')\n",
    "    trans_lst = []\n",
    "    for translation in translations:\n",
    "        trans_lst.append(translation.text)\n",
    "    return trans_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6ec03c5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trans_lst = translator(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fcae1b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Калининград', 100), ('Калининград', 100), ('Калининград', 100), ('Калининград', 100), ('Калининград', 100), ('Калининград', 100), ('Калининград', 100), ('Калининград', 100), ('Калининград', 100), ('Калининград', 100), ('Калининград', 100), ('Калининград', 100), ('Калининград', 100), ('Калининград', 100), ('калининград', 100), ('Калининград', 100), ('Калининград', 100), ('Калининград', 100), ('Калининград', 100), ('Калининград', 100), ('Калининград', 100), ('Калининград', 100), ('Калининград', 100), ('Калининград', 100), ('Калининград', 100), ('Калининград', 100), ('Калининград', 100), ('Калининград', 100), ('Калининград', 100), ('Калининград', 100)]\n"
     ]
    }
   ],
   "source": [
    "result_fuzzy_transl = process.extract(query, trans_lst, limit=None)\n",
    "print(result_fuzzy_transl[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e0eb4613",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_fuzzy_transl = process.extract(query, trans_lst, limit=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864aa869",
   "metadata": {},
   "source": [
    "Для определенного города рассчитаем среднее количество совпадений при использовании переводчика для альтернативных названий:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5abb725e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Levenshtein Distance =  78.61\n"
     ]
    }
   ],
   "source": [
    "accuracy(result_fuzzy_transl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfb69d8",
   "metadata": {},
   "source": [
    "Использовать переводчик на всех альтернативных названиях не будем, так как это занимает достаточно много времени. Составим список с ошибочными запросами и посмотрим на точность:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "30d03891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Ростов', 90), ('Ростов', 90), ('Ростов-на-Дону балһсн', 86), ('Ростов на Дон', 85), ('Ростов на Дону', 81)]\n",
      "[('Казань', 92), ('Казан', 83), ('Козань', 77), ('Къазан', 77), ('Казань ош', 75)]\n",
      "[('Калининград', 82), ('Калининград', 82), ('Калинин', 77), ('Клинци', 75), ('Калињинград', 73)]\n",
      "[('Масква', 100), ('Маскав', 83), ('Москва', 83), ('Москова', 77), ('Москъва', 77)]\n",
      "[('Питер', 90), ('Санкт Петербург', 87), ('Санкт-Петербург', 87), ('Санкт Петерзбург', 84), ('Петербург', 70)]\n"
     ]
    }
   ],
   "source": [
    "for item in test_list:\n",
    "    print(process.extract(item, corp_all, limit=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129b4853-129d-4317-b867-b2ec35be6fb9",
   "metadata": {},
   "source": [
    "Проведенный разбор показал, что использование алгоритма Левенштейна значительно упрощает поиск альтернативных слов, если они переведены. Это повышает вероятность успешного нахождения подобных слов. Можем воспользоваться переводчиком для перевода ошибочных названий городов и найти наиболее похожие города в нашем массиве данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9d89d282-e4ca-4fe8-b8e1-b5c7016cfaf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Rostov', 90), ('Rostov-na-Donu', 89), ('Ostrov', 78), ('Rostokino', 73), ('Protvino', 67)]\n",
      "[('Çay', 90), ('Troitskaya', 71), ('Lukhovitsy', 68), ('Bronnitsy', 68), ('Sremska Mitrovica', 60)]\n",
      "[('Kaliningrad', 82), ('Klin', 68), ('Kolpino', 67), ('Niš', 60), ('Skopin', 60)]\n",
      "[('Moscow', 100), ('Osh', 60), ('Zamoskvorech’ye', 60), ('Primorsko-Akhtarsk', 60), ('Osa', 60)]\n",
      "[('Saint Petersburg', 87), ('Ürgüp', 72), ('Tver', 68), ('Gürsu', 68), ('Suruç', 64)]\n"
     ]
    }
   ],
   "source": [
    "translator= Translator(service_urls=['translate.googleapis.com'])\n",
    "\n",
    "for item in test_list:\n",
    "    trans_word = translator.translate(item, dest='en') \n",
    "    print(process.extract(trans_word.text, names, limit=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6417fa",
   "metadata": {},
   "source": [
    "В нашем исследовании мы применили такие алгоритмы как расстояние `Levenshtein Distance`, `CountVectorizer` и `TfidfVectorizer`. Однако, для улучшения их качества, при поиске наиболее подходящего названия, требуется либо расширить выборку, что может быть эффективно в некоторых случаях, либо использовать переводчик. Однако, полагаться на сторонний API не является оптимальным и эффективным решением, так как это может вызвать проблемы с надежностью сервиса/привести к сбоям. Можем использовать модуль `translate` или транслитерацию, простые питоновские библиотеки, чтобы достичь целей перевода. Исследуем мультиязычные модели и по результатам оценим их точность в поиске альтернативных вариантов написания запросов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b580b0-0c43-4962-be95-4f058cac3907",
   "metadata": {},
   "source": [
    "### SentenceTransformer: модель `stsb-roberta-large`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70435ca6-edd7-4689-9038-d3152051a46d",
   "metadata": {},
   "source": [
    "Для решения задачи семантического текстового сходства, `SentenceTransformers` предлагает использовать предварительно обученную модель `stsb-roberta-large`.\n",
    "\n",
    "`stsb-roberta-large` - это модель, обученная на основе архитектуры `RoBERTa` для выполнения задачи семантической схожести предложений (`Semantic Textual Similarity, STS`). Она была предварительно обучена на большом объеме текстов и тюнингована на задаче STS для обеспечения высокого качества представления семантического содержания предложений. Эта модель позволяет оценивать степень похожести между двумя предложениями.\n",
    "\n",
    "Запустим эту модель и протестируем ее эффективность:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b1462a2b-a0a4-4c47-b461-c112faf16431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d964af4777f94ea5a77548bc6d7f82b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       ".gitattributes:   0%|          | 0.00/748 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed9906e6a802458cbda12ace8154ed3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/191 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61abb12ec09a40189ce5ef38c26b5935",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/3.92k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d76bf5a9c4984f6fb48099d1ebbbbc0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dae645d3e6014e8c801826f8f606c5a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/674 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c26176d4a404418b87b7e1edf382e21c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bee1b89ce054070936fa4e9e4e7619c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9f7ba15aa0e48d6bbfeb97e2534f76b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b867522aa929469b91a76a86e3f55063",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9379c2423d64b1e8b527d8064718b21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f450d8bb77b4591a6a3513ea3f4ba87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f86198f30654b3bb9032cf06b780279",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.17k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "927498b7a7a04c2e8ed85dc52f8a1af1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b74124c60a78406f8aaaeac9f759c223",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_id = 'stsb-roberta-large'\n",
    "roberta = SentenceTransformer(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ced4be7a-b0cd-40f0-968b-f9419d84ec17",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_roberta = roberta.encode(corp_all, convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "418e178d-4a4d-4ae4-a196-2fb28b9dd8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = cities_reloc.name.drop_duplicates().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9019335c-bf33-493a-a310-36f1760c44a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar_roberta(query, top_k=3):\n",
    "    query_embedding = roberta.encode(query, convert_to_tensor=True)\n",
    "    cos_scores = util.cos_sim(query_embedding, embeddings_roberta)\n",
    "    top_results = pd.DataFrame({'name': cities_reloc['name'], 'score': cos_scores.flatten()}).nlargest(top_k, 'score').reset_index(drop=True)\n",
    "    return top_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b13a044-0742-421c-8c76-a0a2eb6c1663",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = ['Растов на Дану', 'Козань', 'Колинингрод', 'Масквэ', 'Сант Петирбург'] \n",
    "result = [find_similar_roberta(_) for _ in query]\n",
    "for r in result:\n",
    "    if not r.empty:\n",
    "        display(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded06adc-a0c7-4b99-93b8-2fffaf3ede27",
   "metadata": {},
   "source": [
    "### SentenceTransformer: модель `LaBSE`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79c894e-be15-422a-adf3-91ead9d51f1e",
   "metadata": {},
   "source": [
    "`LaBSE` (`Language-agnostic BERT Sentence Embeddings`) - это модель глубокого обучения, разработанная для создания векторных представлений предложений на разных языках. Она основана на архитектуре `BERT` (`Bidirectional Encoder Representations from Transformers`) и предоставляет возможность создания семантических векторных представлений предложений, которые могут быть использованы для решения задач обработки естественного языка, таких как поиск похожих предложений, классификация текстов или генерация текстовых описаний. Отличительной особенностью `LaBSE` является ее языконезависимость, что означает, что она может работать с предложениями на разных языках без требования языковых моделей, обученных специально для каждого языка. Это делает `LaBSE` очень гибкой и широко применимой моделью для межъязыковых задач обработки естественного языка. В нашем исследованмм применим эту модель для установления оптимальных названий."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1bff369-4b49-4b67-9ef4-638850fec910",
   "metadata": {},
   "source": [
    "Запустим модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7b77947c-9fec-47ee-a407-de19fcfabcd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "460dd4837c9942e7b850794ba9fd50a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       ".gitattributes:   0%|          | 0.00/391 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ac444db1e314d25be1ddb24eca9b076",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ff053e6fe31490ea5d4389f6f10c921",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "2_Dense/config.json:   0%|          | 0.00/114 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da69c44b558c42c4927bd92d4b853270",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/2.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dd0490c2b224d63b1095c8b3460c500",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/2.19k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5b222a9f26f48fdb076fd3995250144",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/804 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0494ca4cce6b4a88842fc77253effdc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9f095319a4d4094995530cfd863c48f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.88G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adb10c55ceee48a1b1796810b055f36e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e542380049204c818fb890fba65a311d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "334bcb1343c848f492065b984e1a3a52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.62M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f7f208b0c6e48439ae133fd2054d3ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/411 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aea97d45b9754c40a8e49ea3a285db61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/5.22M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c42797e608dc484db18d26a50cf539ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/461 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_id = 'sentence-transformers/LaBSE'\n",
    "labse = SentenceTransformer(model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297d4ce5-df63-4480-93b9-10366c5e3399",
   "metadata": {},
   "source": [
    "Модель не может работать с необработанными списками строк, поэтому каждый пример должен быть преобразован в экземпляр класса `sentence_transformers.InputExample`, а затем загружен в класс `torch.utils.data.DataLoader` для обработки пакетами в случайном порядке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b572226b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_reloc['example'] = cities_reloc[['name', 'alternate_names']].apply(lambda x: InputExample(texts=list(x)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d26cdc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_examples = cities_reloc['example'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9e74d345",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c3160d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = losses.MultipleNegativesRankingLoss(model=labse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5689d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "577ac858eb194aafad32b9f8806d260b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b8dab557ed54caa869312cb013ca23a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1421 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9418e8a16b844e17a318b5dc50ff672d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1421 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labse.fit(train_objectives=[(train_dataloader, train_loss)], epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21949def-0f29-4647-aa80-c05e1fd4402b",
   "metadata": {},
   "source": [
    "Сохраним обученную модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc19b476",
   "metadata": {},
   "outputs": [],
   "source": [
    "labse.save('model_labse_ru_geonames')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b486fac-3bb3-42df-b9e5-756684b5383d",
   "metadata": {},
   "outputs": [],
   "source": [
    "labse = SentenceTransformer('model_labse_ru_geonames')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525ea94f-e6fb-470c-aeff-495a40a4f303",
   "metadata": {},
   "outputs": [],
   "source": [
    "names[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f343b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = labse.encode(names)\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9dbfb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar_labse(geoname, names=names, embeddings=embeddings, model=labse, top_k=3):\n",
    "    result = pd.DataFrame(util.semantic_search(query_embeddings= model.encode(geoname), corpus_embeddings=embeddings, top_k=top_k)[0])\n",
    "    return result.assign(name=names[result.corpus_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c18784-2764-4119-9212-2a30c8ae4e7a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "query = ['Растов на Дану', 'Козань', 'Колинингрод', 'Масквэ', 'Сант Петирбург'] \n",
    "result = [find_similar_labse(_) for _ in query]\n",
    "for r in result:\n",
    "    if not r.empty:\n",
    "        display(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d20279-f9fc-4544-b374-184bea36aff3",
   "metadata": {},
   "source": [
    "Тестовый набор:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9494fb8-5b2f-4849-a805-d600cac654bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_test = geo_test[\"query\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59def6f8-220e-4a84-a6e0-3c678cd4f932",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_metric(def_model):\n",
    "    df_error = pd.DataFrame(columns=[\"query\", \"predict_1\", \"score_1\", \"predict_2\", \"score_2\", \"predict_3\", \"score_3\", \"real_name_in_df\"])\n",
    "    accuracy = 0\n",
    "    for city in range(len(query_test)):\n",
    "        predict = def_model(query_test[city], top_k=3)\n",
    "        if predict.loc[0][\"name\"] == geo_test.loc[city]['name']:\n",
    "            accuracy += 1\n",
    "        else:\n",
    "            df = pd.DataFrame({\n",
    "                \"query\": query_test[city],\n",
    "                \"predict_1\": predict.loc[0][\"name\"], \"score_1\": predict.loc[0][\"score\"],         \n",
    "                \"predict_2\": predict.loc[1][\"name\"],\"score_2\": predict.loc[1][\"score\"],    \n",
    "                \"predict_3\": predict.loc[2][\"name\"], \"score_3\": predict.loc[2][\"score\"], \n",
    "                \"real_name_in_df\": geo_test.loc[city]['name']\n",
    "            }, index=[0])\n",
    "            df_error = pd.concat([df_error, df], ignore_index=True)\n",
    "    display(df_error)\n",
    "    return accuracy/len(query_test)\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a78dfd-1858-40aa-8505-ae75e44eb75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('LaBSE: ', accuracy_metric(find_similar_labse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6c4d3d-cd77-4a9e-9755-0a6ce71c8037",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('RoBERTa: ', accuracy_metric(find_similar_roberta))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05cc6ae9-cf3a-487f-bee4-cf18d6891efb",
   "metadata": {},
   "source": [
    "## Вывод:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7cb7f9c-15f3-44b3-ac27-a55a088be7d5",
   "metadata": {},
   "source": [
    "В этой задаче нам было предложено найти наилучшее решение для подбора названий с `GeoNames`. Мы отфильтровали данные по городам России и некоторым странам, которые являются популярными для релокации, и загрузили их в БД `PostgreSQL`.\n",
    "\n",
    "Мы изучили методы `CountVectorizer` и `TfidfVectorizer`, однако для повышения их качества требовалось либо больше данных для обучения, либо использование базового переводчика, такого как из питоновских библиотек. `Расстояние Левенштейна` (редакционное расстояние) показал хорошие результаты при сравнении строк на одном языке, и даже при наличии ошибок в русских вариантах. Мы также использовали библиотеку `Googletrans`, она выполнила перевод названий и далее было проще находить соответствия городам.\n",
    "\n",
    "Были выбрали две многоязыковые модели для использования: `stsb-roberta-large` и `LaBSE`. Расчёт модели не был продолжен, так требовал достаточно продолжительного времени. Тем не менее, была выстроена логическая цепочка операций до конечного расчета, что позволяет увидеть саму структуру проекта. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
